{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0937b472-37de-4c36-9ec9-485ef5d74ed3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "start epoch. Correct: 0 total:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\bruno/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/200], Loss: 0.5923, Acc: 57763 / 60000\n",
      "start epoch. Correct: 0 total:  0\n",
      "Epoch: [2/200], Loss: 0.0086, Acc: 59318 / 60000\n",
      "start epoch. Correct: 0 total:  0\n",
      "Epoch: [3/200], Loss: 0.0021, Acc: 59559 / 60000\n",
      "start epoch. Correct: 0 total:  0\n",
      "Epoch: [4/200], Loss: 0.0015, Acc: 59684 / 60000\n",
      "start epoch. Correct: 0 total:  0\n",
      "Epoch: [5/200], Loss: 0.1429, Acc: 59795 / 60000\n",
      "start epoch. Correct: 0 total:  0\n",
      "Epoch: [6/200], Loss: 0.0052, Acc: 59829 / 60000\n",
      "start epoch. Correct: 0 total:  0\n",
      "Epoch: [7/200], Loss: 0.0003, Acc: 59860 / 60000\n",
      "start epoch. Correct: 0 total:  0\n",
      "Epoch: [8/200], Loss: 0.0004, Acc: 59903 / 60000\n",
      "start epoch. Correct: 0 total:  0\n",
      "Epoch: [9/200], Loss: 0.0010, Acc: 59908 / 60000\n",
      "start epoch. Correct: 0 total:  0\n",
      "Epoch: [10/200], Loss: 0.0003, Acc: 59933 / 60000\n",
      "start epoch. Correct: 0 total:  0\n",
      "Epoch: [11/200], Loss: 0.0014, Acc: 59954 / 60000\n",
      "start epoch. Correct: 0 total:  0\n",
      "Epoch: [12/200], Loss: 0.0040, Acc: 59952 / 60000\n",
      "start epoch. Correct: 0 total:  0\n",
      "Epoch: [13/200], Loss: 0.0002, Acc: 59958 / 60000\n",
      "start epoch. Correct: 0 total:  0\n",
      "Epoch: [14/200], Loss: 0.0003, Acc: 59964 / 60000\n",
      "start epoch. Correct: 0 total:  0\n",
      "Epoch: [15/200], Loss: 0.0001, Acc: 59970 / 60000\n",
      "start epoch. Correct: 0 total:  0\n",
      "Epoch: [16/200], Loss: 0.0130, Acc: 59974 / 60000\n",
      "start epoch. Correct: 0 total:  0\n",
      "Epoch: [17/200], Loss: 0.0041, Acc: 59972 / 60000\n",
      "start epoch. Correct: 0 total:  0\n",
      "Epoch: [18/200], Loss: 0.0002, Acc: 59989 / 60000\n",
      "start epoch. Correct: 0 total:  0\n",
      "Epoch: [19/200], Loss: 0.0001, Acc: 59987 / 60000\n",
      "start epoch. Correct: 0 total:  0\n",
      "Epoch: [20/200], Loss: 0.0224, Acc: 59983 / 60000\n",
      "start epoch. Correct: 0 total:  0\n",
      "Epoch: [21/200], Loss: 0.0000, Acc: 59985 / 60000\n",
      "start epoch. Correct: 0 total:  0\n",
      "Epoch: [22/200], Loss: 0.0041, Acc: 59987 / 60000\n",
      "start epoch. Correct: 0 total:  0\n",
      "Epoch: [23/200], Loss: 0.0329, Acc: 59980 / 60000\n",
      "start epoch. Correct: 0 total:  0\n",
      "Epoch: [24/200], Loss: 0.0001, Acc: 59987 / 60000\n",
      "start epoch. Correct: 0 total:  0\n",
      "Epoch: [25/200], Loss: 0.0002, Acc: 59988 / 60000\n",
      "start epoch. Correct: 0 total:  0\n",
      "Epoch: [26/200], Loss: 0.0012, Acc: 59992 / 60000\n",
      "start epoch. Correct: 0 total:  0\n",
      "Epoch: [27/200], Loss: 0.0038, Acc: 59988 / 60000\n",
      "start epoch. Correct: 0 total:  0\n",
      "Epoch: [28/200], Loss: 0.0003, Acc: 59984 / 60000\n",
      "start epoch. Correct: 0 total:  0\n",
      "Epoch: [29/200], Loss: 0.0001, Acc: 59993 / 60000\n",
      "start epoch. Correct: 0 total:  0\n",
      "Epoch: [30/200], Loss: 0.0001, Acc: 59993 / 60000\n",
      "start epoch. Correct: 0 total:  0\n",
      "Epoch: [31/200], Loss: 0.0000, Acc: 59996 / 60000\n",
      "start epoch. Correct: 0 total:  0\n",
      "Epoch: [32/200], Loss: 0.0001, Acc: 59985 / 60000\n",
      "start epoch. Correct: 0 total:  0\n",
      "Epoch: [33/200], Loss: 0.0525, Acc: 59978 / 60000\n",
      "start epoch. Correct: 0 total:  0\n",
      "Epoch: [34/200], Loss: 0.0000, Acc: 59977 / 60000\n",
      "start epoch. Correct: 0 total:  0\n",
      "Epoch: [35/200], Loss: 0.0000, Acc: 59992 / 60000\n",
      "start epoch. Correct: 0 total:  0\n",
      "Epoch: [36/200], Loss: 0.0000, Acc: 59984 / 60000\n",
      "start epoch. Correct: 0 total:  0\n",
      "Epoch: [37/200], Loss: 0.0001, Acc: 59981 / 60000\n",
      "start epoch. Correct: 0 total:  0\n",
      "Epoch: [38/200], Loss: 0.0000, Acc: 59984 / 60000\n",
      "start epoch. Correct: 0 total:  0\n",
      "Epoch: [39/200], Loss: 0.0000, Acc: 59991 / 60000\n",
      "start epoch. Correct: 0 total:  0\n",
      "Epoch: [40/200], Loss: 0.0000, Acc: 59989 / 60000\n",
      "start epoch. Correct: 0 total:  0\n",
      "Epoch: [41/200], Loss: 0.0068, Acc: 59987 / 60000\n",
      "start epoch. Correct: 0 total:  0\n",
      "Epoch: [42/200], Loss: 0.0000, Acc: 59994 / 60000\n",
      "start epoch. Correct: 0 total:  0\n",
      "Epoch: [43/200], Loss: 0.0002, Acc: 59995 / 60000\n",
      "start epoch. Correct: 0 total:  0\n",
      "Epoch: [44/200], Loss: 0.0002, Acc: 59985 / 60000\n",
      "start epoch. Correct: 0 total:  0\n",
      "Epoch: [45/200], Loss: 0.0001, Acc: 59997 / 60000\n",
      "start epoch. Correct: 0 total:  0\n",
      "Epoch: [46/200], Loss: 0.0002, Acc: 59999 / 60000\n",
      "start epoch. Correct: 0 total:  0\n",
      "Epoch: [47/200], Loss: 0.0000, Acc: 59998 / 60000\n",
      "start epoch. Correct: 0 total:  0\n",
      "Epoch: [48/200], Loss: 0.0000, Acc: 59999 / 60000\n",
      "start epoch. Correct: 0 total:  0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            #out = ((Input width - filter size + 2* padding) / Stride) + 1\n",
    "            nn.Conv2d(1, 16, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(5, 5),\n",
    "            nn.Conv2d(16, 16, 3),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(144, 120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 10),\n",
    "            nn.Softmax()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #x = x.permute(0, 3, 1, 2)\n",
    "        x = self.net(x)\n",
    "        return x\n",
    "    \n",
    "    def accuracy(self, out, yb):\n",
    "        preds = torch.argmax(out, dim=1)\n",
    "        return (preds == yb).float().mean()\n",
    "\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        pass\n",
    "        #torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_uniform_(m.weight.data)\n",
    "\n",
    "params = {'batch_size': 64,\n",
    "          'shuffle': True}\n",
    "max_epochs = 200\n",
    "\n",
    "start = torch.cuda.Event(enable_timing=True)\n",
    "end = torch.cuda.Event(enable_timing=True)\n",
    "        \n",
    "model = CNN()\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\n",
    "\n",
    "\n",
    "model.cuda()\n",
    "model.apply(weights_init)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.0)\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('/files/', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=64, shuffle=True)\n",
    "\n",
    "start.record()\n",
    "for epochs in range(max_epochs):\n",
    "    # Training\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    print(\"start epoch. Correct:\", correct, \"total: \", total)\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        target = target.to(device)\n",
    "\n",
    "        data = np.repeat(data[..., np.newaxis], 3, -1)\n",
    "        \n",
    "        prediction = model.forward(data[:, 0, :, : ,:].permute(0, 3, 1, 2).to(device))\n",
    "        argmax_predicton = torch.argmax(prediction, dim = 1)\n",
    "    \n",
    "        loss = nn.functional.cross_entropy(prediction, target)\n",
    "        \n",
    "        total += target.size(0)\n",
    "        \n",
    "        correct += (argmax_predicton == target).sum().item()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "    print(f'Epoch: [{epochs+1}/{max_epochs}], Loss: {loss.item():.4f}, Acc: {correct} / {total}')\n",
    "\n",
    "writer.close()\n",
    "end.record()\n",
    "# Waits for everything to finish running\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "print(start.elapsed_time(end)/1000/60, \"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad15ed48-f13c-4f82-baf3-db9d21325f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wall time: 1.97 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from os import path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, BatchSampler, Sampler\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b329823-ac35-4e0a-a7c8-c31ab3e0946c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#out = ((Input width - filter size + 2* padding) / Stride) + 1\n",
    "#dropout = 0 is shortcutted\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, img_shape=128, label_shape=8, channel_numbers=[3,16], number_of_c_layers = 2, number_of_filters=[16,16], \n",
    "                 kernel_sizes=[3,3], strides=[1,1], paddings=[0,0], fclayout = [120, 32], maxpool = [4, 4], device = \"cuda\", BN=False, dropout_rate = 0):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.device = device\n",
    "        self.channel_number = channel_numbers\n",
    "        self.number_of_filters = number_of_filters\n",
    "        self.kernel_sizes = kernel_sizes\n",
    "        self.strides = strides\n",
    "        self.paddings = paddings\n",
    "        self.maxpool = maxpool\n",
    "        self.fclayout = fclayout\n",
    "        self.fcs = []\n",
    "        self.label_shape = label_shape\n",
    "        self.img_shape = img_shape\n",
    "        self.dropout_rate = dropout_rate\n",
    "            \n",
    "        self.net = nn.Sequential()\n",
    "        \n",
    "        for i in range(number_of_c_layers): \n",
    "            if i == number_of_c_layers-1:\n",
    "                self.net.add_module(\"conv2-\" + str(i), nn.Conv2d(channel_numbers[i], number_of_filters[i], kernel_sizes[i], stride=strides[i], padding=paddings[i]))\n",
    "                if BN:\n",
    "                    self.net.add_module(\"BN-2d-\" + str(i), nn.BatchNorm2d(number_of_filters[i]))\n",
    "                self.net.add_module(\"relu-conv-\" + str(i), nn.ReLU())\n",
    "            else:\n",
    "                self.net.add_module(\"conv2-\" + str(i), nn.Conv2d(channel_numbers[i], number_of_filters[i], kernel_sizes[i], stride=strides[i], padding=paddings[i]))\n",
    "                if BN:\n",
    "                    self.net.add_module(\"BN-2d-\" + str(i), nn.BatchNorm2d(number_of_filters[i]))\n",
    "                self.net.add_module(\"relu-conv-\" + str(i), nn.ReLU())\n",
    "                self.net.add_module(\"maxpool-\" + str(i), nn.MaxPool2d(maxpool[i], maxpool[i]))\n",
    "        \n",
    "        self.net.add_module(\"flatten1\", nn.Flatten())\n",
    "        \n",
    "        fc_down = self.net(torch.rand(1, channel_numbers[0], img_shape, img_shape)).size()[1]\n",
    "        print(fc_down)\n",
    "        \n",
    "        self.net.add_module(\"fc-0\", nn.Linear(fc_down, self.fclayout[0]))\n",
    "        if BN:\n",
    "            print(\"BN3: \", self.fclayout[0])\n",
    "            self.net.add_module(\"BN-1d-0\", nn.BatchNorm1d(self.fclayout[0]))\n",
    "        self.net.add_module(\"Drop-0\", nn.Dropout(dropout_rate))\n",
    "        self.net.add_module(\"relu-fc-0\", nn.ReLU())\n",
    "        \n",
    "        for i in range(len(fclayout)):\n",
    "            if i == len(self.fclayout)-1:\n",
    "                self.net.add_module(\"fc-\" + str(i+1), nn.Linear(fclayout[i], self.label_shape))\n",
    "            else:\n",
    "                self.net.add_module(\"fc-\" + str(i+1), nn.Linear(fclayout[i], fclayout[i+1]))\n",
    "                if BN:\n",
    "                    print(\"BN: \" + str(i+1), fclayout[i+1])\n",
    "                    self.net.add_module(\"BN-1d-\" + str(i+1), nn.BatchNorm1d(fclayout[i+1]))\n",
    "                self.net.add_module(\"Drop-\" + str(i+1), nn.Dropout(dropout_rate))\n",
    "                self.net.add_module(\"relu-fc-\" + str(i+1), nn.ReLU())\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        return x\n",
    "\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_uniform_(m.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b2a90fe3-b362-44ca-973e-276607df3353",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=False)\n",
    "#model.add_module(\"fc\", nn.Linear(512, 8))\n",
    "\n",
    "def training(trainingloader, max_epochs, optimizer, model, validationloader=None, run_name=\"\", l1_lambda = 0):\n",
    "    \n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    \n",
    "    metrics_tracker = pd.DataFrame(columns=['epoch', 'train_loss', 'train_accuracy','val_loss', 'val_accuracy'])\n",
    "    epochs_list = []\n",
    "    train_loss_list = []\n",
    "    train_accuracy_list = []\n",
    "    val_loss_list = []\n",
    "    val_accuracy_list = []\n",
    "    \n",
    "    start.record()\n",
    "    for epochs in range(max_epochs):\n",
    "        # Training\n",
    "        correct = 0\n",
    "        total_labels = 0\n",
    "        total_loss = 0\n",
    "        for batch_idx, (data, target) in enumerate(trainingloader):\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "            target = target.to(device)\n",
    "\n",
    "            data = np.repeat(data[..., np.newaxis], 3, -1)\n",
    "        \n",
    "            prediction = model.forward(data[:, 0, :, : ,:].permute(0, 3, 1, 2).to(device))\n",
    "            \n",
    "            argmax_predicton = torch.argmax(prediction, dim = 1)\n",
    "\n",
    "            with torch.cuda.amp.autocast():\n",
    "                loss = nn.functional.cross_entropy(prediction, target)\n",
    "            \n",
    "            if l1_lambda != 0:\n",
    "                l1_norm = sum(p.abs().sum() for p in model.parameters())\n",
    "\n",
    "                loss = loss + l1_lambda * l1_norm\n",
    "\n",
    "            #loss gets updated after each batch, so a total loss is better to see if model is improving\n",
    "            total_loss += loss\n",
    "\n",
    "            total_labels += target.size(0)\n",
    "            correct += (argmax_predicton == target).sum().item()\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "        print(f'Epoch: [{epochs+1}/{max_epochs}], total train (sum of) Loss: {total_loss}, Train Acc: {correct} / {total_labels}')\n",
    "        epochs_list.append(epochs+1)\n",
    "        train_loss_list.append(total_loss.cpu().detach())\n",
    "        train_accuracy_list.append(correct/total_labels)\n",
    "        \n",
    "    metrics_tracker = [{'epoch': epochs_list[i], 'train_loss': train_loss_list[i].item(), 'train_accuracy': train_accuracy_list[i], 'val_loss': val_loss_list[i].item(), 'val_accuracy': val_accuracy_list[i]} for i in range(max_epochs)]\n",
    "    \n",
    "    end.record()\n",
    "    # Waits for everything to finish running\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    print(start.elapsed_time(end)/1000/60, \"min\")\n",
    "    torch.cuda.empty_cache()\n",
    "    return pd.DataFrame(metrics_tracker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c9fa6abf-d141-4540-9855-76d595c4bc34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6272\n",
      "Epoch: [1/200], total train (sum of) Loss: 390.8134460449219, Train Acc: 52550 / 60000\n",
      "Epoch: [2/200], total train (sum of) Loss: 178.5899658203125, Train Acc: 56557 / 60000\n",
      "Epoch: [3/200], total train (sum of) Loss: 135.96829223632812, Train Acc: 57350 / 60000\n",
      "Epoch: [4/200], total train (sum of) Loss: 109.54197692871094, Train Acc: 57844 / 60000\n",
      "Epoch: [5/200], total train (sum of) Loss: 92.8230972290039, Train Acc: 58136 / 60000\n",
      "Epoch: [6/200], total train (sum of) Loss: 80.80097961425781, Train Acc: 58383 / 60000\n",
      "Epoch: [7/200], total train (sum of) Loss: 70.76211547851562, Train Acc: 58610 / 60000\n",
      "Epoch: [8/200], total train (sum of) Loss: 63.27030944824219, Train Acc: 58742 / 60000\n",
      "Epoch: [9/200], total train (sum of) Loss: 55.80248260498047, Train Acc: 58874 / 60000\n",
      "Epoch: [10/200], total train (sum of) Loss: 49.409366607666016, Train Acc: 59008 / 60000\n",
      "Epoch: [11/200], total train (sum of) Loss: 44.17115783691406, Train Acc: 59120 / 60000\n",
      "Epoch: [12/200], total train (sum of) Loss: 39.93252944946289, Train Acc: 59168 / 60000\n",
      "Epoch: [13/200], total train (sum of) Loss: 35.77438735961914, Train Acc: 59295 / 60000\n",
      "Epoch: [14/200], total train (sum of) Loss: 32.91593933105469, Train Acc: 59306 / 60000\n",
      "Epoch: [15/200], total train (sum of) Loss: 29.972579956054688, Train Acc: 59374 / 60000\n",
      "Epoch: [16/200], total train (sum of) Loss: 26.05927085876465, Train Acc: 59472 / 60000\n",
      "Epoch: [17/200], total train (sum of) Loss: 24.961885452270508, Train Acc: 59463 / 60000\n",
      "Epoch: [18/200], total train (sum of) Loss: 22.056861877441406, Train Acc: 59558 / 60000\n",
      "Epoch: [19/200], total train (sum of) Loss: 19.42848777770996, Train Acc: 59599 / 60000\n",
      "Epoch: [20/200], total train (sum of) Loss: 17.619821548461914, Train Acc: 59640 / 60000\n",
      "Epoch: [21/200], total train (sum of) Loss: 16.379941940307617, Train Acc: 59642 / 60000\n",
      "Epoch: [22/200], total train (sum of) Loss: 15.141432762145996, Train Acc: 59680 / 60000\n",
      "Epoch: [23/200], total train (sum of) Loss: 11.325109481811523, Train Acc: 59789 / 60000\n",
      "Epoch: [24/200], total train (sum of) Loss: 10.517189025878906, Train Acc: 59808 / 60000\n",
      "Epoch: [25/200], total train (sum of) Loss: 9.324441909790039, Train Acc: 59842 / 60000\n",
      "Epoch: [26/200], total train (sum of) Loss: 9.716133117675781, Train Acc: 59798 / 60000\n",
      "Epoch: [27/200], total train (sum of) Loss: 6.800346851348877, Train Acc: 59879 / 60000\n",
      "Epoch: [28/200], total train (sum of) Loss: 7.33030891418457, Train Acc: 59862 / 60000\n",
      "Epoch: [29/200], total train (sum of) Loss: 7.386988162994385, Train Acc: 59855 / 60000\n",
      "Epoch: [30/200], total train (sum of) Loss: 4.288407802581787, Train Acc: 59935 / 60000\n",
      "Epoch: [31/200], total train (sum of) Loss: 3.8406312465667725, Train Acc: 59940 / 60000\n",
      "Epoch: [32/200], total train (sum of) Loss: 3.0176634788513184, Train Acc: 59962 / 60000\n",
      "Epoch: [33/200], total train (sum of) Loss: 2.407029390335083, Train Acc: 59975 / 60000\n",
      "Epoch: [34/200], total train (sum of) Loss: 1.4813140630722046, Train Acc: 59987 / 60000\n",
      "Epoch: [35/200], total train (sum of) Loss: 1.2538516521453857, Train Acc: 59991 / 60000\n",
      "Epoch: [36/200], total train (sum of) Loss: 0.9238764047622681, Train Acc: 59998 / 60000\n",
      "Epoch: [37/200], total train (sum of) Loss: 0.8297257423400879, Train Acc: 59995 / 60000\n",
      "Epoch: [38/200], total train (sum of) Loss: 1.2285517454147339, Train Acc: 59989 / 60000\n",
      "Epoch: [39/200], total train (sum of) Loss: 0.6541720032691956, Train Acc: 59999 / 60000\n",
      "Epoch: [40/200], total train (sum of) Loss: 0.5405810475349426, Train Acc: 60000 / 60000\n",
      "Epoch: [41/200], total train (sum of) Loss: 0.48524710536003113, Train Acc: 60000 / 60000\n",
      "Epoch: [42/200], total train (sum of) Loss: 0.4589536786079407, Train Acc: 60000 / 60000\n",
      "Epoch: [43/200], total train (sum of) Loss: 0.4228825867176056, Train Acc: 60000 / 60000\n",
      "Epoch: [44/200], total train (sum of) Loss: 0.4118683934211731, Train Acc: 60000 / 60000\n",
      "Epoch: [45/200], total train (sum of) Loss: 0.38044723868370056, Train Acc: 60000 / 60000\n",
      "Epoch: [46/200], total train (sum of) Loss: 0.36205264925956726, Train Acc: 60000 / 60000\n",
      "Epoch: [47/200], total train (sum of) Loss: 0.37374165654182434, Train Acc: 59999 / 60000\n",
      "Epoch: [48/200], total train (sum of) Loss: 0.34116747975349426, Train Acc: 60000 / 60000\n",
      "Epoch: [49/200], total train (sum of) Loss: 0.31026899814605713, Train Acc: 60000 / 60000\n",
      "Epoch: [50/200], total train (sum of) Loss: 0.30046162009239197, Train Acc: 60000 / 60000\n",
      "Epoch: [51/200], total train (sum of) Loss: 0.2840113043785095, Train Acc: 60000 / 60000\n",
      "Epoch: [52/200], total train (sum of) Loss: 0.27258631587028503, Train Acc: 60000 / 60000\n",
      "Epoch: [53/200], total train (sum of) Loss: 0.604571521282196, Train Acc: 59994 / 60000\n",
      "Epoch: [54/200], total train (sum of) Loss: 0.2949554920196533, Train Acc: 60000 / 60000\n",
      "Epoch: [55/200], total train (sum of) Loss: 0.2565288543701172, Train Acc: 60000 / 60000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7452/3741772826.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m   batch_size=64, shuffle=True)\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"testt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7452/4055436435.py\u001b[0m in \u001b[0;36mtraining\u001b[1;34m(trainingloader, max_epochs, optimizer, model, validationloader, run_name, l1_lambda)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m             \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m             \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[0;32m    336\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer_state\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"found_inf_per_device\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"No inf checks were recorded for this optimizer.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 338\u001b[1;33m         \u001b[0mretval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_opt_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    339\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m         \u001b[0moptimizer_state\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"stage\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOptState\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSTEPPED\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py\u001b[0m in \u001b[0;36m_maybe_opt_step\u001b[1;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[0;32m    282\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_maybe_opt_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m         \u001b[0mretval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 284\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"found_inf_per_device\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    285\u001b[0m             \u001b[0mretval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    282\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_maybe_opt_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m         \u001b[0mretval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 284\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"found_inf_per_device\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    285\u001b[0m             \u001b[0mretval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "params = {'batch_size': 64,\n",
    "          'shuffle': True}\n",
    "max_epochs = 200\n",
    "\n",
    "start = torch.cuda.Event(enable_timing=True)\n",
    "end = torch.cuda.Event(enable_timing=True)\n",
    "        \n",
    "#model = CNN()\n",
    "#model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\n",
    "model = CNN(img_shape=28, label_shape=10, number_of_c_layers = 2, number_of_filters=[16,32], channel_numbers=[3,16], maxpool=[2,2], kernel_sizes=[1,1], strides=[1,1], paddings=[0,0], fclayout=[200,32])#, dropout_rate = dropout)\n",
    "\n",
    "model.cuda()\n",
    "model.apply(weights_init)\n",
    "print(model)\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('/files/', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=64, shuffle=True)\n",
    "\n",
    "results = training(train_loader, max_epochs, torch.optim.SGD(model.parameters(),lr=0.01), model, train_loader, run_name=\"testt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
